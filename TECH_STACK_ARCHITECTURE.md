# ğŸ—ï¸ Technical Architecture & Tech Stack

## Complete System Architecture Documentation

---

## ğŸ“Š System Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Streamlit Web Interface                      â”‚
â”‚                        (User Interface)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Debate Orchestrator                           â”‚
â”‚              (Coordinates agent interactions)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼           â–¼           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Pro Agent â”‚ â”‚ Con Agent â”‚ â”‚Judge Agentâ”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚             â”‚             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Hybrid RAG Retriever â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼           â–¼           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  FAISS   â”‚  â”‚  BM25   â”‚  â”‚  Ollama â”‚
        â”‚ (Vector) â”‚  â”‚(Keyword)â”‚  â”‚  (LLM)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– Agent Architecture

### Core Agent Components

Each `DebateAgent` instance consists of:

```python
class DebateAgent:
    # Identity & Role
    name: str                    # Agent identifier
    role: AgentRole              # PRO, CON, or JUDGE
    personality: str             # Role-specific behavior description
    
    # AI Components
    llm: OllamaLLM              # Language model (or None for simulated)
    retriever: HybridRetriever  # RAG system (optional)
    
    # Memory Systems
    conversation_history: List[Dict]  # Debate history
    evidence_used: List[Document]     # Retrieved documents
    
    # Performance Tracking
    metrics: Dict[str, Any]     # Performance metrics
```

---

## ğŸ› ï¸ Tech Stack Breakdown

### **Frontend Layer**

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **UI Framework** | Streamlit | 1.40.1 | Web interface |
| **Visualization** | Streamlit Charts | Built-in | Performance graphs |
| **Styling** | Custom HTML/CSS | - | UI enhancements |

### **Backend Layer**

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Language** | Python | 3.8+ | Core logic |
| **LLM Framework** | LangChain | 0.3.7 | Agent framework |
| **LLM Provider** | Ollama | 0.4.3 | Local LLM |
| **LLM Integration** | langchain-ollama | 0.2.0 | Ollama wrapper |

### **RAG (Retrieval) Layer**

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Vector DB** | FAISS | 1.9.0 | Semantic search |
| **Embeddings** | Sentence-Transformers | 3.3.1 | Text embeddings |
| **Keyword Search** | Rank-BM25 | 0.2.2 | BM25 algorithm |
| **Document Processing** | LangChain Community | 0.3.5 | Loaders & splitters |

### **Monitoring Layer**

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Process Monitor** | psutil | 6.1.0 | Memory tracking |
| **Time Tracking** | Python time | Built-in | Response times |
| **Metrics Storage** | Python dict | Built-in | In-memory metrics |

### **Utilities**

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Environment** | python-dotenv | - | Config management |
| **Data Processing** | pandas | - | Data manipulation |
| **Arrays** | numpy | - | Numerical operations |

---

## ğŸ§  Agent-Specific Tech Stack

### **1. PRO Agent**

#### Core Technologies
```python
Agent Configuration:
â”œâ”€â”€ LLM: Ollama (llama3:8b - 4.7GB)
â”œâ”€â”€ Temperature: 0.7
â”œâ”€â”€ Context Window: 8192 tokens
â””â”€â”€ Specialization: Logical reasoning, structured arguments
```

#### Tools & Capabilities
- **Text Generation**: OllamaLLM with llama3:8b
- **Document Retrieval**: HybridRetriever (FAISS + BM25)
- **Context Management**: 8K token window
- **Memory**: Conversation history list

#### Memory Structure
```python
{
    'conversation_history': [
        {
            'topic': 'AI underwriting',
            'response': 'I argue in favor...',
            'timestamp': datetime,
            'round': 1
        }
    ],
    'evidence_used': [
        Document(
            page_content='...',
            metadata={
                'source': 'file.txt',
                'relevance_score': 0.95,
                'confidence': 'High',
                'rank': 1
            }
        )
    ],
    'metrics': {
        'response_times': [1.2, 1.5, 1.3],
        'token_counts': [150, 180, 165],
        'memory_usage': [2.3, 2.5, 2.4],
        'model_used': 'llama3:8b'
    }
}
```

---

### **2. CON Agent**

#### Core Technologies
```python
Agent Configuration:
â”œâ”€â”€ LLM: Ollama (llama3:8b - 4.7GB)
â”œâ”€â”€ Temperature: 0.7
â”œâ”€â”€ Context Window: 8192 tokens
â””â”€â”€ Specialization: Critical analysis, counter-arguments
```

#### Tools & Capabilities
- **Text Generation**: OllamaLLM with llama3:8b
- **Document Retrieval**: HybridRetriever (FAISS + BM25)
- **Context Management**: 8K token window
- **Memory**: Conversation history + opponent arguments

#### Memory Structure
```python
{
    'conversation_history': [
        {
            'topic': 'AI underwriting',
            'response': 'I argue against...',
            'opponent_args': ['Pro argument 1', 'Pro argument 2'],
            'timestamp': datetime,
            'round': 1
        }
    ],
    'evidence_used': [Document(...)],
    'metrics': {...}
}
```

---

### **3. JUDGE Agent**

#### Core Technologies
```python
Agent Configuration:
â”œâ”€â”€ LLM: Ollama (mistral:7b - 4.1GB)
â”œâ”€â”€ Temperature: 0.7
â”œâ”€â”€ Context Window: 8192 tokens
â””â”€â”€ Specialization: Balanced evaluation, objective analysis
```

#### Tools & Capabilities
- **Text Generation**: OllamaLLM with mistral:7b
- **Document Retrieval**: HybridRetriever (FAISS + BM25)
- **Multi-Argument Analysis**: Processes all PRO/CON arguments
- **Verdict Generation**: Synthesizes comprehensive evaluation

#### Memory Structure
```python
{
    'conversation_history': [
        {
            'topic': 'AI underwriting',
            'all_arguments': [
                'Pro: argument 1',
                'Con: argument 1',
                'Pro: argument 2',
                'Con: argument 2'
            ],
            'verdict': 'Based on evidence...',
            'timestamp': datetime
        }
    ],
    'evidence_used': [Document(...)],
    'metrics': {...}
}
```

---

## ğŸ” Retrieval-Augmented Generation (RAG) Stack

### **Hybrid Retriever Architecture**

```python
HybridRetriever:
â”œâ”€â”€ Semantic Search (FAISS)
â”‚   â”œâ”€â”€ Embeddings: sentence-transformers/all-MiniLM-L6-v2
â”‚   â”œâ”€â”€ Vector Dimension: 384
â”‚   â”œâ”€â”€ Index Type: Flat (L2 distance)
â”‚   â””â”€â”€ Similarity: Cosine similarity
â”‚
â”œâ”€â”€ Keyword Search (BM25)
â”‚   â”œâ”€â”€ Algorithm: Okapi BM25
â”‚   â”œâ”€â”€ Parameters: k1=1.5, b=0.75
â”‚   â””â”€â”€ Tokenization: Word-level
â”‚
â””â”€â”€ Fusion Strategy
    â”œâ”€â”€ Alpha: 0.5 (configurable)
    â”œâ”€â”€ Semantic Weight: 50%
    â””â”€â”€ Keyword Weight: 50%
```

### **Document Processing Pipeline**

```
Raw Documents
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document Loader â”‚ (PyPDF, TextLoader, DirectoryLoader)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Splitter  â”‚ (RecursiveCharacterTextSplitter)
â”‚  Chunk: 1000    â”‚
â”‚  Overlap: 100   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embeddings    â”‚ (SentenceTransformer)
â”‚   Model: L6-v2  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Store   â”‚ (FAISS Index)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hybrid Search  â”‚ (FAISS + BM25)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **RAG Configuration**

```python
RAG Settings:
â”œâ”€â”€ Chunk Size: 1000 characters
â”œâ”€â”€ Chunk Overlap: 100 characters
â”œâ”€â”€ Embedding Model: all-MiniLM-L6-v2 (384 dimensions)
â”œâ”€â”€ Vector DB: FAISS (Flat index)
â”œâ”€â”€ Keyword Search: BM25 (k1=1.5, b=0.75)
â”œâ”€â”€ Hybrid Alpha: 0.5
â”œâ”€â”€ Default K (results): 3-5 documents
â”œâ”€â”€ Semantic K: 10 documents
â””â”€â”€ BM25 K: 10 documents
```

---

## ğŸ’¾ Memory Management

### **Agent Memory Types**

#### 1. **Short-Term Memory** (Conversation History)
```python
# Stored per debate round
conversation_history: List[Dict] = [
    {
        'topic': str,           # Current debate topic
        'response': str,        # Agent's response
        'round': int,           # Debate round number
        'timestamp': datetime,  # When generated
        'opponent_args': List[str]  # For context
    }
]
```

#### 2. **Evidence Memory** (Retrieved Documents)
```python
# Accumulated throughout debate
evidence_used: List[Document] = [
    Document(
        page_content: str,      # Document text
        metadata: {
            'source': str,      # File name
            'chunk_id': int,    # Chunk number
            'relevance_score': float,  # 0.0-1.0
            'confidence': str,  # High/Medium/Low
            'rank': int         # Position in results
        }
    )
]
```

#### 3. **Performance Memory** (Metrics)
```python
# Real-time performance tracking
metrics: Dict[str, Any] = {
    'response_times': List[float],     # Seconds per response
    'token_counts': List[int],         # Tokens per response
    'memory_usage': List[float],       # MB per response
    'total_responses': int,            # Total count
    'avg_response_time': float,        # Average seconds
    'total_tokens': int,               # Cumulative tokens
    'peak_memory_mb': float,           # Peak usage
    'model_used': str                  # Model identifier
}
```

### **Memory Persistence**

| Memory Type | Persistence | Scope | Cleanup |
|-------------|-------------|-------|---------|
| **Conversation** | Session | Per debate | Manual clear |
| **Evidence** | Session | Per debate | Manual clear |
| **Metrics** | Session | Per agent | On app restart |
| **Vector DB** | Disk | Global | Manual rebuild |
| **Session State** | Session | Global | On disconnect |

---

## ğŸ¯ Context Management

### **Context Window Management**

Each agent manages context through multiple layers:

#### **Layer 1: System Prompt** (Static)
```python
system_prompt = f"""You are {agent.name}, an AI agent in insurance debate.

Role: {agent.role}
Personality: {agent.personality}

Responsibilities:
- Analyze insurance policies and trends
- Provide evidence-based arguments
- Cite sources when making claims
- Stay focused on insurance topics
"""
```

#### **Layer 2: Retrieved Context** (Dynamic)
```python
retrieved_context = """
[Source 1: insurance_trends_2025.txt] [Relevance: 1.0] [Confidence: High]
AI-powered underwriting systems have demonstrated...

[Source 2: market_analysis.txt] [Relevance: 0.9] [Confidence: High]
Industry adoption continues to accelerate...

[Source 3: risk_guidelines.pdf] [Relevance: 0.8] [Confidence: Medium]
Traditional methods face scaling challenges...
"""
```

#### **Layer 3: Opponent Arguments** (Dynamic)
```python
opponent_arguments = [
    "Pro: AI underwriting increases efficiency by 35%...",
    "Con: Privacy concerns remain unaddressed...",
    "Pro: Cost savings benefit consumers..."
]
```

#### **Layer 4: Current Topic** (Dynamic)
```python
topic = "AI-powered underwriting should be mandatory in insurance"
```

### **Complete Prompt Assembly**

```python
final_prompt = f"""
{system_prompt}

TOPIC: {topic}

RETRIEVED EVIDENCE:
{retrieved_context}

PREVIOUS ARGUMENTS:
{opponent_arguments}

YOUR TASK: Provide your {agent.role} perspective on this topic.
Use the evidence above to support your argument.
"""
```

### **Context Token Budget**

| Component | Typical Tokens | Max Tokens | Priority |
|-----------|---------------|------------|----------|
| **System Prompt** | ~200 | 500 | High |
| **Topic** | ~20 | 100 | High |
| **Retrieved Docs** | ~1500 | 3000 | Medium |
| **Opponent Args** | ~800 | 2000 | Medium |
| **Response Buffer** | ~500 | 2000 | High |
| **Safety Margin** | ~1000 | - | - |
| **Total Available** | ~4020 | 8192 | - |

---

## ğŸ”§ Tool Integration

### **Available Tools per Agent**

#### **Core Tools (All Agents)**

1. **Text Generation**
   ```python
   Tool: OllamaLLM
   Input: Prompt (string)
   Output: Generated text (string)
   Model: llama3:8b / mistral:7b
   Temperature: 0.7
   Max Tokens: 2000
   ```

2. **Document Retrieval**
   ```python
   Tool: HybridRetriever
   Input: Query (string), K (int)
   Output: List[Document]
   Method: FAISS + BM25 hybrid search
   Default K: 3
   ```

3. **Context Formatting**
   ```python
   Tool: format_context()
   Input: List[Document]
   Output: Formatted string
   Features: Source citations, relevance scores
   ```

4. **Performance Tracking**
   ```python
   Tool: Built-in metrics system
   Tracks: Time, tokens, memory
   Storage: In-memory dictionary
   Access: get_metrics() method
   ```

#### **Specialized Tools**

**Judge Agent Only:**
- Multi-argument analysis
- Verdict synthesis
- Comparative evaluation

---

## ğŸ“Š Data Flow Architecture

### **Debate Execution Flow**

```
User Input (Topic)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Debate Orchestrator â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    For each round:
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Pro Agentâ”‚  â”‚Con Agentâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â”‚ (1) Retrieve Context
     â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hybrid Retriever    â”‚
â”‚  (FAISS + BM25)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ (2) Documents + Metadata
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
     â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Pro Agentâ”‚  â”‚Con Agentâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â”‚ (3) Format Context + Build Prompt
     â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ollama  â”‚  â”‚ Ollama  â”‚
â”‚ LLM     â”‚  â”‚ LLM     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â”‚ (4) Generated Response
     â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Pro Agentâ”‚  â”‚Con Agentâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â”‚ (5) Store in Memory + Track Metrics
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â–¼
     (Next round or Judge)
            â”‚
            â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚Judge (if â”‚
      â”‚enabled)  â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ (6) Collect all arguments
           â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Ollama   â”‚
     â”‚mistral:7b â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ (7) Verdict
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Display   â”‚
    â”‚   Results   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—„ï¸ Storage Architecture

### **Vector Database (FAISS)**

```
vectorstore/
â””â”€â”€ faiss_index/
    â”œâ”€â”€ index.faiss          # Vector index (binary)
    â”œâ”€â”€ index.pkl            # Document metadata (pickle)
    â””â”€â”€ docstore.pkl         # Document store (pickle)

Format: Binary (efficient storage)
Size: ~1-5MB per 1000 documents
Index Type: Flat L2 (brute force, accurate)
Persistence: Disk-based
Load Time: ~100-500ms
```

### **Session State (Streamlit)**

```python
st.session_state = {
    'debate_history': List[Dict],      # Past debates
    'orchestrator': DebateOrchestrator, # Current orchestrator
    'retriever': HybridRetriever,      # RAG system
    'current_agents': List[DebateAgent] # Active agents
}

Persistence: Browser session
Storage: In-memory (RAM)
Lifetime: Until page refresh/close
```

### **Configuration (Files)**

```
Project Root/
â”œâ”€â”€ config.py              # System configuration
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ kb_docs/              # Knowledge base
    â””â”€â”€ (user documents)
```

---

## âš¡ Performance Specifications

### **Resource Requirements**

| Component | Min RAM | Recommended RAM | Disk Space |
|-----------|---------|-----------------|------------|
| **Streamlit App** | 200 MB | 500 MB | Minimal |
| **FAISS Index** | 50 MB | 200 MB | ~5 MB |
| **Ollama llama3:8b** | 6 GB | 8 GB | 4.7 GB |
| **Ollama mistral:7b** | 5 GB | 7 GB | 4.1 GB |
| **Python Runtime** | 100 MB | 300 MB | Minimal |
| **Total System** | 8 GB | 16 GB | 10 GB |

### **Performance Benchmarks**

| Operation | Time | Notes |
|-----------|------|-------|
| **App Startup** | 2-5s | Load dependencies |
| **Vector DB Load** | 0.1-0.5s | FAISS index |
| **Document Retrieval** | 0.05-0.2s | Hybrid search |
| **LLM Response (llama3:8b)** | 1-3s | 150 tokens |
| **LLM Response (mistral:7b)** | 0.8-2s | 150 tokens |
| **Full Debate (2 rounds)** | 8-15s | Without RAG |
| **Full Debate (2 rounds + RAG)** | 10-20s | With retrieval |

---

## ğŸ” Security & Privacy

### **Data Flow Security**

| Layer | Data | Security Measure |
|-------|------|------------------|
| **User Input** | Debate topics | Client-side only |
| **Retrieved Docs** | KB documents | Local processing |
| **LLM Processing** | All prompts | Local Ollama (no external API) |
| **Responses** | Generated text | Session-only storage |
| **Metrics** | Performance data | In-memory only |

### **Privacy Features**

âœ… **100% Local Processing** - No external API calls  
âœ… **No Data Logging** - No persistent storage of debates  
âœ… **Session-Based** - Data cleared on disconnect  
âœ… **Offline Capable** - Works without internet  
âœ… **User Control** - All data stays on local machine  

---

## ğŸ”„ Scalability Considerations

### **Current Architecture**

| Aspect | Current | Scalable To | Method |
|--------|---------|-------------|--------|
| **Concurrent Debates** | 1 | 10+ | Threading/Async |
| **Agents per Debate** | 2-3 | 10+ | List scaling |
| **Documents in KB** | 100s | 10,000+ | FAISS handles well |
| **Debate History** | 10s | 1000+ | Database needed |
| **Concurrent Users** | 1 | 100+ | Multi-instance |

### **Scaling Strategies**

**Horizontal Scaling:**
- Deploy multiple Streamlit instances
- Load balance with nginx
- Shared vector database
- Redis for session state

**Vertical Scaling:**
- Upgrade to GPU for faster LLM
- Increase RAM for more agents
- SSD for faster vector DB access

---

## ğŸ“š Summary: Complete Tech Stack

### **Core Technologies**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PRESENTATION LAYER            â”‚
â”‚  Streamlit 1.40.1 + HTML/CSS           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          APPLICATION LAYER              â”‚
â”‚  Python 3.8+ + LangChain 0.3.7         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             AI/ML LAYER                 â”‚
â”‚  Ollama 0.4.3 (llama3:8b, mistral:7b)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            RETRIEVAL LAYER              â”‚
â”‚  FAISS 1.9.0 + BM25 0.2.2              â”‚
â”‚  Sentence-Transformers 3.3.1            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MONITORING LAYER              â”‚
â”‚  psutil 6.1.0 + Python time            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Per-Agent Stack Summary**

**Each agent uses:**
- âœ… LangChain for orchestration
- âœ… Ollama for text generation
- âœ… FAISS + BM25 for retrieval
- âœ… Custom memory management
- âœ… Performance tracking with psutil
- âœ… Context management system
- âœ… Evidence scoring system

---

## ğŸ“ Key Takeaways

1. **Fully Local Stack** - No external dependencies
2. **Modular Architecture** - Easy to swap components
3. **Production-Ready** - Monitoring and metrics built-in
4. **Scalable Design** - Can handle growth
5. **Open Source** - All components are FOSS
6. **Resource Efficient** - Runs on consumer hardware
7. **Privacy-First** - All processing local

---

**This is a modern, professional AI debate system built with industry-standard tools!** ğŸš€
